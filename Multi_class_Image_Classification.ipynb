{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPl2Xibt/tRZ4A73GipjOfX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maulik-vyas/Tensors-Fundamentals/blob/main/Multi_class_Image_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3d08UX6gz6i",
        "outputId": "e539dcd0-bc86-4215-e01d-e5878c4b54fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-18 17:38:05--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.194.128, 74.125.200.128, 74.125.68.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.194.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 519183241 (495M) [application/zip]\n",
            "Saving to: ‘10_food_classes_all_data.zip’\n",
            "\n",
            "10_food_classes_all 100%[===================>] 495.13M  20.0MB/s    in 27s     \n",
            "\n",
            "2023-03-18 17:38:32 (18.4 MB/s) - ‘10_food_classes_all_data.zip’ saved [519183241/519183241]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"10_food_classes_all_data.zip\", \"r\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "for dirpath, dirnames, filenames in os.walk(\"10_food_classes_all_data\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPeydoiQi5Gb",
        "outputId": "0029c510-9e1d-46da-a79d-f32e27c6b40b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 images in '10_food_classes_all_data'.\n",
            "There are 10 directories and 0 images in '10_food_classes_all_data/train'.\n",
            "There are 0 directories and 750 images in '10_food_classes_all_data/train/ice_cream'.\n",
            "There are 0 directories and 750 images in '10_food_classes_all_data/train/steak'.\n",
            "There are 0 directories and 750 images in '10_food_classes_all_data/train/ramen'.\n",
            "There are 0 directories and 750 images in '10_food_classes_all_data/train/grilled_salmon'.\n",
            "There are 0 directories and 750 images in '10_food_classes_all_data/train/fried_rice'.\n",
            "There are 0 directories and 750 images in '10_food_classes_all_data/train/hamburger'.\n",
            "There are 0 directories and 750 images in '10_food_classes_all_data/train/sushi'.\n",
            "There are 0 directories and 750 images in '10_food_classes_all_data/train/chicken_wings'.\n",
            "There are 0 directories and 750 images in '10_food_classes_all_data/train/chicken_curry'.\n",
            "There are 0 directories and 750 images in '10_food_classes_all_data/train/pizza'.\n",
            "There are 10 directories and 0 images in '10_food_classes_all_data/test'.\n",
            "There are 0 directories and 250 images in '10_food_classes_all_data/test/ice_cream'.\n",
            "There are 0 directories and 250 images in '10_food_classes_all_data/test/steak'.\n",
            "There are 0 directories and 250 images in '10_food_classes_all_data/test/ramen'.\n",
            "There are 0 directories and 250 images in '10_food_classes_all_data/test/grilled_salmon'.\n",
            "There are 0 directories and 250 images in '10_food_classes_all_data/test/fried_rice'.\n",
            "There are 0 directories and 250 images in '10_food_classes_all_data/test/hamburger'.\n",
            "There are 0 directories and 250 images in '10_food_classes_all_data/test/sushi'.\n",
            "There are 0 directories and 250 images in '10_food_classes_all_data/test/chicken_wings'.\n",
            "There are 0 directories and 250 images in '10_food_classes_all_data/test/chicken_curry'.\n",
            "There are 0 directories and 250 images in '10_food_classes_all_data/test/pizza'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"10_food_classes_all_data/train/\"\n",
        "test_dir = \"10_food_classes_all_data/test/\""
      ],
      "metadata": {
        "id": "TqrmGenVkJZD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import numpy as np\n",
        "data_dir = pathlib.Path(train_dir)\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*')]))\n",
        "print(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilbnwDlgl_PC",
        "outputId": "81e589f8-0eb8-4150-c7f0-29bb0bbee53c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['chicken_curry' 'chicken_wings' 'fried_rice' 'grilled_salmon' 'hamburger'\n",
            " 'ice_cream' 'pizza' 'ramen' 'steak' 'sushi']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(train_dir,\n",
        "                                               target_size=(224, 224),\n",
        "                                               batch_size=32,\n",
        "                                               class_mode='categorical')\n",
        "\n",
        "test_data = test_datagen.flow_from_directory(test_dir,\n",
        "                                             target_size=(224, 224),\n",
        "                                             batch_size=32,\n",
        "                                             class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dv-0yyHqnacu",
        "outputId": "420ee5cb-55c8-4d5b-d2c6-e588acbe5013"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7500 images belonging to 10 classes.\n",
            "Found 2500 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Activation\n",
        "\n",
        "model8 = Sequential([\n",
        "    Conv2D(10, 3, input_shape=(224, 224, 3)),\n",
        "    Activation(activation='relu'),\n",
        "    Conv2D(10, 3, activation='relu'),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(10, 3, activation='relu'),\n",
        "    Conv2D(10, 3, activation='relu'),\n",
        "    MaxPool2D(),\n",
        "    Flatten(),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model8.compile(loss='categorical_crossentropy',\n",
        "               optimizer=tf.keras.optimizers.Adam(),\n",
        "               metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "7iLPS6nx84R5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history8 = model8.fit(train_data,\n",
        "                      epochs=5,\n",
        "                      steps_per_epoch=len(train_data),\n",
        "                      validation_data=test_data,\n",
        "                      validation_steps=len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeZOtbIbA6fd",
        "outputId": "ddb7f46c-264d-4e04-aa33-443eec080371"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "235/235 [==============================] - 62s 215ms/step - loss: 2.1190 - accuracy: 0.2408 - val_loss: 1.9318 - val_accuracy: 0.3336\n",
            "Epoch 2/5\n",
            "235/235 [==============================] - 48s 206ms/step - loss: 1.7827 - accuracy: 0.3929 - val_loss: 1.8749 - val_accuracy: 0.3492\n",
            "Epoch 3/5\n",
            "235/235 [==============================] - 49s 207ms/step - loss: 1.3542 - accuracy: 0.5504 - val_loss: 2.1029 - val_accuracy: 0.2992\n",
            "Epoch 4/5\n",
            "235/235 [==============================] - 49s 210ms/step - loss: 0.7138 - accuracy: 0.7707 - val_loss: 2.8020 - val_accuracy: 0.2984\n",
            "Epoch 5/5\n",
            "235/235 [==============================] - 49s 208ms/step - loss: 0.2457 - accuracy: 0.9271 - val_loss: 3.6837 - val_accuracy: 0.2568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model8.evaluate(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeqBHu_iCod2",
        "outputId": "cf56b2da-f7a5-42f6-88c5-7114e8a871e8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 12s 149ms/step - loss: 3.6837 - accuracy: 0.2568\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.683680772781372, 0.25679999589920044]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model9 = Sequential([\n",
        "    Conv2D(10, 3, input_shape=(224, 224, 3)),\n",
        "    Activation(activation='relu'),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(10, 3, activation='relu'),\n",
        "    MaxPool2D(),\n",
        "    Flatten(),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model9.compile(loss='categorical_crossentropy',\n",
        "               optimizer=tf.keras.optimizers.Adam(),\n",
        "               metrics=[\"accuracy\"])\n",
        "\n",
        "history9 = model9.fit(train_data,\n",
        "                      epochs=5,\n",
        "                      steps_per_epoch=len(train_data),\n",
        "                      validation_data=test_data,\n",
        "                      validation_steps=len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KA_m1pPzEuhH",
        "outputId": "6ace275c-f499-4236-e0e3-bc99bd849132"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "235/235 [==============================] - 49s 203ms/step - loss: 2.1244 - accuracy: 0.2361 - val_loss: 1.9464 - val_accuracy: 0.3016\n",
            "Epoch 2/5\n",
            "235/235 [==============================] - 47s 199ms/step - loss: 1.7603 - accuracy: 0.4035 - val_loss: 1.9574 - val_accuracy: 0.3280\n",
            "Epoch 3/5\n",
            "235/235 [==============================] - 46s 197ms/step - loss: 1.3410 - accuracy: 0.5652 - val_loss: 1.9698 - val_accuracy: 0.3428\n",
            "Epoch 4/5\n",
            "235/235 [==============================] - 46s 197ms/step - loss: 0.8371 - accuracy: 0.7415 - val_loss: 2.3560 - val_accuracy: 0.3228\n",
            "Epoch 5/5\n",
            "235/235 [==============================] - 46s 195ms/step - loss: 0.4377 - accuracy: 0.8800 - val_loss: 2.6926 - val_accuracy: 0.3136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen_augmented = ImageDataGenerator(rescale=1/255.,\n",
        "                                          rotation_range=0.2,\n",
        "                                          horizontal_flip=True,\n",
        "                                          height_shift_range=0.2,\n",
        "                                          width_shift_range=0.2,\n",
        "                                          zoom_range=0.2,\n",
        "                                          )\n",
        "\n",
        "train_data_augmented = train_datagen_augmented.flow_from_directory(train_dir,\n",
        "                                                                   target_size=(224, 224),\n",
        "                                                                   batch_size=32,\n",
        "                                                                   class_mode=\"categorical\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2KtsaApJWcg",
        "outputId": "7eb2c1cb-b467-45de-dc37-e9d0ef00256e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7500 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model10 = tf.keras.models.clone_model(model8)\n",
        "\n",
        "model10.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "history10 = model10.fit(train_data_augmented,\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data_augmented),\n",
        "                        validation_data=test_data,\n",
        "                        validation_steps=len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fng5hd3bNRH2",
        "outputId": "cdbf48dc-7e9f-4646-f70e-9bfebbdaf290"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "235/235 [==============================] - 117s 491ms/step - loss: 2.2227 - accuracy: 0.1773 - val_loss: 2.0800 - val_accuracy: 0.2668\n",
            "Epoch 2/5\n",
            "235/235 [==============================] - 116s 493ms/step - loss: 2.0505 - accuracy: 0.2808 - val_loss: 1.8846 - val_accuracy: 0.3292\n",
            "Epoch 3/5\n",
            "235/235 [==============================] - 115s 491ms/step - loss: 1.9654 - accuracy: 0.3161 - val_loss: 1.9441 - val_accuracy: 0.3328\n",
            "Epoch 4/5\n",
            "235/235 [==============================] - 125s 534ms/step - loss: 1.9159 - accuracy: 0.3345 - val_loss: 1.7512 - val_accuracy: 0.3944\n",
            "Epoch 5/5\n",
            "235/235 [==============================] - 116s 493ms/step - loss: 1.8852 - accuracy: 0.3484 - val_loss: 1.8195 - val_accuracy: 0.3876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model8.evaluate(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LJzHU6uOUpI",
        "outputId": "af911905-f794-48e2-e450-b61f081da9db"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 11s 145ms/step - loss: 3.6837 - accuracy: 0.2568\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.6836817264556885, 0.25679999589920044]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model10.evaluate(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnAuMc2gRUJr",
        "outputId": "3df881ad-f5e9-490e-9705-b04b0f3d0ecb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 12s 149ms/step - loss: 1.8195 - accuracy: 0.3876\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.819521427154541, 0.38760000467300415]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H2Vij58bRZ5i"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}